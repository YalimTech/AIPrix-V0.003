import { PrismaClient } from '@prisma/client';

const prisma = new PrismaClient();

async function checkCurrentLLM() {
  try {
    console.log('üß™ Verificando qu√© LLM est√°n usando nuestros agentes...');
    
    // 1. Obtener configuraci√≥n de ElevenLabs
    const config = await prisma.accountElevenLabsConfig.findFirst({
      include: {
        account: true
      }
    });
    
    if (!config || !config.apiKey) {
      console.log('‚ùå No se encontr√≥ API Key de ElevenLabs');
      return;
    }
    
    console.log(`‚úÖ API Key encontrada para: ${config.account.email}`);
    
    // 2. Obtener agentes existentes
    console.log('\n2Ô∏è‚É£ Obteniendo agentes existentes...');
    
    const agentsResponse = await fetch('https://api.elevenlabs.io/v1/convai/agents', {
      headers: {
        'xi-api-key': config.apiKey,
      },
    });
    
    if (!agentsResponse.ok) {
      console.log('‚ùå Error al obtener agentes');
      return;
    }
    
    const agents = await agentsResponse.json();
    console.log(`‚úÖ Se encontraron ${agents.agents?.length || 0} agentes existentes`);
    
    if (agents.agents && agents.agents.length > 0) {
      console.log('\n3Ô∏è‚É£ Analizando LLM de cada agente:');
      
      for (let i = 0; i < Math.min(5, agents.agents.length); i++) {
        const agent = agents.agents[i];
        console.log(`\n   Agente ${i + 1}: ${agent.name}`);
        console.log(`   - Agent ID: ${agent.agent_id}`);
        
        // Obtener detalles del agente
        const agentDetailsResponse = await fetch(`https://api.elevenlabs.io/v1/convai/agents/${agent.agent_id}`, {
          headers: {
            'xi-api-key': config.apiKey,
          },
        });
        
        if (agentDetailsResponse.ok) {
          const agentDetails = await agentDetailsResponse.json();
          const llm = agentDetails.conversation_config?.agent?.prompt?.llm;
          const temperature = agentDetails.conversation_config?.agent?.prompt?.temperature;
          const maxTokens = agentDetails.conversation_config?.agent?.prompt?.max_tokens;
          const reasoningEffort = agentDetails.conversation_config?.agent?.prompt?.reasoning_effort;
          const thinkingBudget = agentDetails.conversation_config?.agent?.prompt?.thinking_budget;
          
          console.log(`   - LLM: ${llm || 'No especificado'}`);
          console.log(`   - Temperature: ${temperature}`);
          console.log(`   - Max Tokens: ${maxTokens}`);
          console.log(`   - Reasoning Effort: ${reasoningEffort}`);
          console.log(`   - Thinking Budget: ${thinkingBudget}`);
          
          // Verificar si tiene herramientas
          const tools = agentDetails.conversation_config?.agent?.prompt?.tools;
          const builtInTools = agentDetails.conversation_config?.agent?.prompt?.built_in_tools;
          console.log(`   - Tools: ${tools?.length || 0} herramientas personalizadas`);
          console.log(`   - Built-in Tools: ${Object.keys(builtInTools || {}).length} herramientas integradas`);
          
          // Mostrar herramientas integradas activas
          if (builtInTools) {
            const activeTools = Object.entries(builtInTools).filter(([key, value]) => value !== null);
            if (activeTools.length > 0) {
              console.log(`   - Herramientas activas: ${activeTools.map(([key]) => key).join(', ')}`);
            }
          }
        } else {
          console.log(`   ‚ùå Error al obtener detalles del agente`);
        }
      }
      
      // 4. Mostrar resumen de LLMs utilizados
      console.log('\n4Ô∏è‚É£ Resumen de LLMs utilizados:');
      const llmCounts = {};
      
      for (const agent of agents.agents) {
        const agentDetailsResponse = await fetch(`https://api.elevenlabs.io/v1/convai/agents/${agent.agent_id}`, {
          headers: {
            'xi-api-key': config.apiKey,
          },
        });
        
        if (agentDetailsResponse.ok) {
          const agentDetails = await agentDetailsResponse.json();
          const llm = agentDetails.conversation_config?.agent?.prompt?.llm || 'No especificado';
          llmCounts[llm] = (llmCounts[llm] || 0) + 1;
        }
      }
      
      for (const [llm, count] of Object.entries(llmCounts)) {
        console.log(`   - ${llm}: ${count} agentes`);
      }
      
      // 5. Verificar qu√© LLMs est√°n disponibles
      console.log('\n5Ô∏è‚É£ LLMs disponibles en ElevenLabs:');
      console.log('   - gemini-2.0-flash: Modelo r√°pido de Google');
      console.log('   - gpt-4o-mini: Modelo eficiente de OpenAI');
      console.log('   - gpt-4o: Modelo avanzado de OpenAI');
      console.log('   - claude-3-5-sonnet: Modelo de Anthropic');
      console.log('   - claude-3-5-haiku: Modelo r√°pido de Anthropic');
      
      // 6. Recomendaciones
      console.log('\n6Ô∏è‚É£ Recomendaciones:');
      console.log('   - Para agentes en espa√±ol: gemini-2.0-flash (actual)');
      console.log('   - Para m√°xima calidad: gpt-4o');
      console.log('   - Para velocidad: gpt-4o-mini');
      console.log('   - Para an√°lisis complejo: claude-3-5-sonnet');
      
    } else {
      console.log('‚ùå No se encontraron agentes');
    }
    
  } catch (error) {
    console.error('‚ùå Error durante la verificaci√≥n:', error);
  } finally {
    await prisma.$disconnect();
  }
}

checkCurrentLLM();
